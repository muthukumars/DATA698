*** No CODEPAGE record, no encoding_override: will use 'ascii'
     casenum  year  month   age  ... others2  sumbands    subset  abm
0          1  78.0    1.0   4.0  ...     0.0  2.000000      test  1.0
1          2  78.0   12.0   1.0  ...     NaN  3.099000  training  1.0
2          3  78.0    3.0   0.8  ...     0.0       NaN      test  NaN
3          4  78.0    8.0  54.0  ...     NaN  5.108999  training  1.0
4          5   NaN    NaN   NaN  ...     NaN       NaN      test  0.0
..       ...   ...    ...   ...  ...     ...       ...       ...  ...
576      577  70.0    7.0   2.0  ...     0.0       NaN      test  1.0
577      578  70.0    7.0  23.0  ...     0.0       NaN  training  0.0
578      579  70.0    8.0   8.0  ...     0.0       NaN      test  0.0
579      580  70.0    7.0   1.0  ...     0.0       NaN  training  NaN
580      581  70.0    7.0  13.0  ...     NaN       NaN      test  1.0

[581 rows x 43 columns]
*** No CODEPAGE record, no encoding_override: will use 'ascii'
         1    78   1.1     4  1.2    0  ...  0.8  100.1  0.9  0.10         2  1.7
0      2.0  78.0  12.0   1.0  1.0  0.0  ...  0.0    0.0  0.0   0.0  3.099000  1.0
1      3.0  78.0   3.0   0.8  0.0  1.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
2      4.0  78.0   8.0  54.0  6.0  2.0  ...  0.0    0.0  0.0   0.0  5.108999  1.0
3      5.0   0.0   0.0   0.0  0.0  0.0  ...  0.0    0.0  0.0   0.0  0.000000  0.0
4      6.0   0.0   0.0   0.0  0.0  0.0  ...  0.0    0.0  0.0   0.0  0.000000  0.0
..     ...   ...   ...   ...  ...  ...  ...  ...    ...  ...   ...       ...  ...
575  577.0  70.0   7.0   2.0  3.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  1.0
576  578.0  70.0   7.0  23.0  4.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
577  579.0  70.0   8.0   8.0  4.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
578  580.0  70.0   7.0   1.0  0.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
579  581.0  70.0   7.0  13.0  6.0  2.0  ...  0.0    0.0  0.0   0.0  0.000000  1.0

[580 rows x 40 columns]
------For % of percent testing  set---ABM----Gaussian
25.0
________________________________________
------Accuracy Score-------
90.3448275862069
------Confusion Matrix----
[[75  8]
 [ 6 56]]
-----ClasificationReport------
              precision    recall  f1-score   support

         0.0       0.93      0.90      0.91        83
         1.0       0.88      0.90      0.89        62

    accuracy                           0.90       145
   macro avg       0.90      0.90      0.90       145
weighted avg       0.90      0.90      0.90       145

------For % of percent testing  set-ABM----Gaussian-
40.0
________________________________________
------Accuracy Score-------
89.65517241379311
------Confusion Matrix----
[[125  16]
 [  8  83]]
-----ClasificationReport------
              precision    recall  f1-score   support

         0.0       0.94      0.89      0.91       141
         1.0       0.84      0.91      0.87        91

    accuracy                           0.90       232
   macro avg       0.89      0.90      0.89       232
weighted avg       0.90      0.90      0.90       232

*** No CODEPAGE record, no encoding_override: will use 'ascii'
     casenum  year  month   age  ... others2  sumbands    subset  abm
0          1  78.0    1.0   4.0  ...     0.0  2.000000      test  1.0
1          2  78.0   12.0   1.0  ...     NaN  3.099000  training  1.0
2          3  78.0    3.0   0.8  ...     0.0       NaN      test  NaN
3          4  78.0    8.0  54.0  ...     NaN  5.108999  training  1.0
4          5   NaN    NaN   NaN  ...     NaN       NaN      test  0.0
..       ...   ...    ...   ...  ...     ...       ...       ...  ...
576      577  70.0    7.0   2.0  ...     0.0       NaN      test  1.0
577      578  70.0    7.0  23.0  ...     0.0       NaN  training  0.0
578      579  70.0    8.0   8.0  ...     0.0       NaN      test  0.0
579      580  70.0    7.0   1.0  ...     0.0       NaN  training  NaN
580      581  70.0    7.0  13.0  ...     NaN       NaN      test  1.0

[581 rows x 43 columns]
*** No CODEPAGE record, no encoding_override: will use 'ascii'
         1    78   1.1     4  1.2    0  ...  0.8  100.1  0.9  0.10         2  1.7
0      2.0  78.0  12.0   1.0  1.0  0.0  ...  0.0    0.0  0.0   0.0  3.099000  1.0
1      3.0  78.0   3.0   0.8  0.0  1.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
2      4.0  78.0   8.0  54.0  6.0  2.0  ...  0.0    0.0  0.0   0.0  5.108999  1.0
3      5.0   0.0   0.0   0.0  0.0  0.0  ...  0.0    0.0  0.0   0.0  0.000000  0.0
4      6.0   0.0   0.0   0.0  0.0  0.0  ...  0.0    0.0  0.0   0.0  0.000000  0.0
..     ...   ...   ...   ...  ...  ...  ...  ...    ...  ...   ...       ...  ...
575  577.0  70.0   7.0   2.0  3.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  1.0
576  578.0  70.0   7.0  23.0  4.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
577  579.0  70.0   8.0   8.0  4.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
578  580.0  70.0   7.0   1.0  0.0  0.0  ...  0.0  100.0  0.0   0.0  0.000000  0.0
579  581.0  70.0   7.0  13.0  6.0  2.0  ...  0.0    0.0  0.0   0.0  0.000000  1.0

[580 rows x 40 columns]
------For % of percent testing  set---ABM----Gaussian
25.0
________________________________________
------Accuracy Score-------
90.3448275862069
------Confusion Matrix----
[[75  8]
 [ 6 56]]
-----ClasificationReport------
              precision    recall  f1-score   support

         0.0       0.93      0.90      0.91        83
         1.0       0.88      0.90      0.89        62

    accuracy                           0.90       145
   macro avg       0.90      0.90      0.90       145
weighted avg       0.90      0.90      0.90       145

------For % of percent testing  set-ABM----Gaussian-
40.0
________________________________________
------Accuracy Score-------
89.65517241379311
------Confusion Matrix----
[[125  16]
 [  8  83]]
-----ClasificationReport------
              precision    recall  f1-score   support

         0.0       0.94      0.89      0.91       141
         1.0       0.84      0.91      0.87        91

    accuracy                           0.90       232
   macro avg       0.89      0.90      0.89       232
weighted avg       0.90      0.90      0.90       232

